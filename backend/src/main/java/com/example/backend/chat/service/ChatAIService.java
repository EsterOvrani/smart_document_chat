package com.example.backend.chat.service;

import com.example.backend.chat.dto.AskQuestionRequest;
import com.example.backend.chat.dto.AnswerResponse;
import com.example.backend.chat.mapper.MessageMapper;
import com.example.backend.chat.model.Chat;
import com.example.backend.chat.model.Message;
import com.example.backend.chat.model.Message.MessageRole;
import com.example.backend.chat.repository.ChatRepository;
import com.example.backend.chat.repository.MessageRepository;
import com.example.backend.common.infrastructure.vectordb.QdrantVectorService;
import com.example.backend.user.model.User;
import com.example.backend.common.exception.ResourceNotFoundException;
import com.example.backend.common.exception.ValidationException;
import com.example.backend.common.exception.ExternalServiceException;
import com.example.backend.common.exception.UnauthorizedException;

import dev.langchain4j.data.segment.TextSegment;
import dev.langchain4j.data.embedding.Embedding;
import dev.langchain4j.model.embedding.EmbeddingModel;
import dev.langchain4j.model.openai.OpenAiChatModel;
import dev.langchain4j.model.openai.OpenAiTokenizer;
import dev.langchain4j.model.output.Response;
import dev.langchain4j.store.embedding.EmbeddingMatch;
import dev.langchain4j.store.embedding.EmbeddingSearchRequest;
import dev.langchain4j.store.embedding.EmbeddingSearchResult;
import dev.langchain4j.store.embedding.EmbeddingStore;
import dev.langchain4j.data.message.AiMessage;
import dev.langchain4j.data.message.SystemMessage;
import dev.langchain4j.data.message.UserMessage;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.cache.annotation.CacheEvict;
import org.springframework.cache.annotation.Cacheable;
import org.springframework.data.domain.PageRequest;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.ArrayList;
import java.util.List;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
@Slf4j
@Transactional
public class ChatAIService {

    private final ChatRepository chatRepository;
    private final MessageRepository messageRepository;
    private final MessageMapper messageMapper;
    private final QdrantVectorService qdrantVectorService;
    private final EmbeddingModel embeddingModel;
    private final OpenAiChatModel chatModel;

    private static final int DEFAULT_CONTEXT_MESSAGES = 5;
    private static final int MAX_RELEVANT_CHUNKS = 5;

    // ==================== Ask Question (with Cache Eviction) ====================

    /**
     * Process a user question and generate AI response
     * 
     * Cache Strategy:
     * - @CacheEvict clears chatMessages and recentMessages caches
     * - Executed AFTER the method completes (beforeInvocation = false)
     * - Ensures next read will fetch updated messages including new Q&A
     * 
     * Why evict cache?
     * Because we're adding 2 new messages (user question + AI answer)
     * Old cached data would be stale
     */
    @CacheEvict(
        value = {"chatMessages", "recentMessages"},  // Clear both caches
        key = "#chatId",                              // For this specific chat
        beforeInvocation = false                      // Evict AFTER method completes
    )
    public AnswerResponse askQuestion(Long chatId, AskQuestionRequest request, User user) {
        log.info("ğŸ’¬ Processing question for chat: {} from user: {}", 
            chatId, user.getUsername());

        long startTime = System.currentTimeMillis();

        try {
            // Validate chat and request
            Chat chat = validateAndGetChat(chatId, user);
            validateRequest(request);

            if (!chat.isReady()) {
                throw new ValidationException(
                    "chat", 
                    "×”×©×™×—×” ×¢×“×™×™×Ÿ ×œ× ××•×›× ×”. ×¡×˜×˜×•×¡: " + chat.getStatus()
                );
            }

            // Save user's question
            Message userMessage = saveUserMessage(request.getQuestion(), chat, user);
            log.info("âœ… User message saved with ID: {}", userMessage.getId());

            // Get conversation context
            List<Message> contextMessages = getContextMessages(
                chat, 
                request.getContextMessageCount() != null 
                    ? request.getContextMessageCount() 
                    : DEFAULT_CONTEXT_MESSAGES
            );

            // Search relevant documents
            List<RelevantDocument> relevantDocs = searchRelevantDocuments(chat, request.getQuestion());

            if (relevantDocs.isEmpty()) {
                return createNoResultsResponse(userMessage);
            }

            // Build messages for AI
            List<dev.langchain4j.data.message.ChatMessage> messages = buildChatMessages(
                request.getQuestion(),
                contextMessages,
                relevantDocs
            );

            // Call OpenAI
            Response<AiMessage> response = chatModel.generate(messages);
            String answer = response.content().text();
            
            long responseTime = System.currentTimeMillis() - startTime;
            Double confidence = calculateConfidence(relevantDocs);
            
            OpenAiTokenizer tokenizer = new OpenAiTokenizer("gpt-4");
            int tokensUsed = tokenizer.estimateTokenCountInMessage(response.content());

            List<AnswerResponse.Source> sources = buildSources(relevantDocs);

            // Save AI's answer
            Message assistantMessage = saveAssistantMessage(
                answer,
                sources,
                confidence,
                tokensUsed,
                responseTime,
                chat,
                userMessage.getId()
            );

            // Build response
            AnswerResponse answerResponse = AnswerResponse.builder()
                .answer(answer)
                .success(true)
                .confidence(confidence)
                .sources(sources)
                .messageId(assistantMessage.getId())
                .tokensUsed(tokensUsed)
                .responseTimeMs(responseTime)
                .timestamp(LocalDateTime.now())
                .build();

            log.info("âœ… Question answered successfully in {}ms", responseTime);
            
            // â­ Cache will be automatically evicted after this method completes
            // Due to @CacheEvict annotation above
            
            return answerResponse;

        } catch (ValidationException | UnauthorizedException | ResourceNotFoundException e) {
            throw e;  
        } catch (Exception e) {
            log.error("âŒ Failed to answer question for chat: {}", chatId, e);
            return createErrorResponse(e.getMessage());
        }
    }

    // ==================== Get Messages (with Caching) ====================

    /**
     * Retrieve chat message history
     * 
     * Cache Strategy:
     * - @Cacheable caches the result in "chatMessages" cache
     * - Key is the chatId
     * - TTL: 30 minutes (configured in RedisConfig)
     * - unless="#result.isEmpty()" â†’ Don't cache if no messages found
     * 
     * Performance:
     * - First call: ~25ms (PostgreSQL query)
     * - Subsequent calls: ~2ms (Redis lookup)
     * - 12x faster!
     */
    @Transactional(readOnly = true)
    @Cacheable(
        value = "chatMessages",       // Cache name
        key = "#chatId",               // Cache key: chat ID
        unless = "#result.isEmpty()"  // Don't cache empty results
    )
    public List<Message> getChatHistory(Long chatId, User user) {
        log.info("ğŸ” getChatHistory called for chatId: {}", chatId);
        log.info("âš ï¸ This will be cached! Next calls will be instant.");
        
        try {
            Chat chat = validateAndGetChat(chatId, user);
            log.info("âœ… Chat found: {}, Title: {}", chat.getId(), chat.getTitle());
            
            List<Message> messages = messageRepository.findByChatOrderByCreatedAtAsc(chat);
            log.info("âœ… Found {} messages for chat {} (from DB)", messages.size(), chatId);
            
            if (messages.isEmpty()) {
                log.warn("âš ï¸ No messages found for chat {}", chatId);
            }
            
            return messages;
            
        } catch (ResourceNotFoundException e) {
            throw e; // ××¢×‘×™×¨ ×”×œ××” ××ª ×”×—×¨×™×’×” ×”××§×•×¨×™×ª
        } catch (UnauthorizedException e) {
            throw e; // ××¢×‘×™×¨ ×”×œ××” ××ª ×”×—×¨×™×’×” ×”××§×•×¨×™×ª
        } catch (Exception e) {
            log.error("âŒ Error getting chat history for chatId: {}", chatId, e);
            throw ExternalServiceException.vectorDbError("× ×›×©×œ ×‘×§×‘×œ×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”");
        }
    }

    /**
     * Retrieve recent N messages from a chat
     * 
     * Cache Strategy:
     * - Separate cache from full history ("recentMessages")
     * - Shorter TTL: 10 minutes (changes more frequently)
     * - Key includes both chatId AND limit (different queries cached separately)
     * 
     * Use Case:
     * - Used for context in AI responses
     * - Only needs last 5-10 messages
     * - No need to load entire conversation
     */
    @Cacheable(
        value = "recentMessages",
        key = "#chatId + '_' + #limit",  // Composite key: "1_5" for chat 1, limit 5
        unless = "#result.isEmpty()"
    )
    public List<Message> getRecentMessages(Long chatId, int limit) {
        log.info("ğŸ” getRecentMessages called for chatId: {} (limit: {})", chatId, limit);
        log.info("âš ï¸ This will be cached for 10 minutes");
        
        Chat chat = new Chat();
        chat.setId(chatId);
        
        List<Message> messages = messageRepository
            .findByChatOrderByCreatedAtDesc(chat, PageRequest.of(0, limit));
        
        java.util.Collections.reverse(messages);
        
        log.info("âœ… Found {} recent messages (from DB)", messages.size());
        return messages;
    }

    // ==================== Helper Methods (no changes) ====================

    private Chat validateAndGetChat(Long chatId, User user) {
        Chat chat = chatRepository.findByIdAndActiveTrue(chatId)
            .orElseThrow(() -> new ResourceNotFoundException("×©×™×—×”", chatId));
        
        if (!chat.getUser().getId().equals(user.getId())) {
            throw new UnauthorizedException("×©×™×—×”", chatId);
        }
        
        return chat;
    }

    private void validateRequest(AskQuestionRequest request) {
        request.validateContextCount();
        if (!request.isValid()) {
            throw new IllegalArgumentException("Invalid question");
        }
    }

    private Message saveUserMessage(String question, Chat chat, User user) {
        Message message = new Message();
        message.setContent(question);
        message.setRole(MessageRole.USER);
        message.setChat(chat);
        message.setUser(user);
        message.setCreatedAt(LocalDateTime.now());
        return messageRepository.save(message);
    }

    private List<Message> getContextMessages(Chat chat, int count) {
        if (count <= 0) {
            return new ArrayList<>();
        }

        // â­ This will use the cached recentMessages!
        return getRecentMessages(chat.getId(), count);
    }

    private List<RelevantDocument> searchRelevantDocuments(Chat chat, String question) {
        try {
            EmbeddingStore<TextSegment> embeddingStore = 
                qdrantVectorService.getEmbeddingStoreForCollection(chat.getVectorCollectionName());

            if (embeddingStore == null) {
                log.error("âŒ No embedding store found for collection: {}", chat.getVectorCollectionName());
                return new ArrayList<>();
            }

            Embedding queryEmbedding = embeddingModel.embed(question).content();

            EmbeddingSearchRequest searchRequest = EmbeddingSearchRequest.builder()
                .queryEmbedding(queryEmbedding)
                .maxResults(MAX_RELEVANT_CHUNKS)
                .minScore(0.5)
                .build();

            EmbeddingSearchResult<TextSegment> searchResult = embeddingStore.search(searchRequest);
            List<EmbeddingMatch<TextSegment>> matches = searchResult.matches();

            log.info("âœ… Found {} relevant chunks", matches.size());

            List<RelevantDocument> relevantDocs = new ArrayList<>();
            for (EmbeddingMatch<TextSegment> match : matches) {
                RelevantDocument doc = new RelevantDocument();
                doc.setText(match.embedded().text());
                doc.setScore(match.score());
                
                if (match.embedded().metadata() != null) {
                    String docIdStr = match.embedded().metadata().getString("document_id");
                    if (docIdStr != null) {
                        doc.setDocumentId(Long.parseLong(docIdStr));
                    } else {
                        doc.setDocumentId(0L);
                    }
                    
                    String docName = match.embedded().metadata().getString("document_name");
                    doc.setDocumentName(docName != null ? docName : "Unknown");
                }
                
                relevantDocs.add(doc);
            }

            return relevantDocs;

        } catch (Exception e) {
            log.error("âŒ Failed to search relevant documents", e);
            return new ArrayList<>();
        }
    }

    private List<dev.langchain4j.data.message.ChatMessage> buildChatMessages(
            String question,
            List<Message> contextMessages,
            List<RelevantDocument> relevantDocs) {

        List<dev.langchain4j.data.message.ChatMessage> messages = new ArrayList<>();

        messages.add(SystemMessage.from(
            "You are a helpful AI assistant that answers questions based on documents. " +
            "IMPORTANT: Answer in the SAME LANGUAGE as the question! " +
            "If the question is in Hebrew - answer in Hebrew. If in English - answer in English. " +
            "Answer clearly and accurately. Base your answer only on the provided document information. " +
            "If there isn't enough information, say so clearly."
        ));

        for (Message msg : contextMessages) {
            if (msg.getRole() == MessageRole.USER) {
                messages.add(UserMessage.from(msg.getContent()));
            } else if (msg.getRole() == MessageRole.ASSISTANT) {
                messages.add(AiMessage.from(msg.getContent()));
            }
        }

        StringBuilder context = new StringBuilder();
        context.append("Relevant information from documents:\n\n");
        
        for (int i = 0; i < relevantDocs.size(); i++) {
            RelevantDocument doc = relevantDocs.get(i);
            context.append(String.format("[Document %d - %s]:\n%s\n\n",
                i + 1,
                doc.getDocumentName(),
                doc.getText()
            ));
        }

        messages.add(UserMessage.from(context.toString() + "\nQuestion: " + question));

        return messages;
    }

    private Message saveAssistantMessage(
            String answer,
            List<AnswerResponse.Source> sources,
            Double confidence,
            Integer tokensUsed,
            Long responseTime,
            Chat chat,
            Long parentMessageId) {

        Message message = new Message();
        message.setContent(answer);
        message.setRole(MessageRole.ASSISTANT);
        message.setChat(chat);
        message.setParentMessageId(parentMessageId);
        message.setConfidenceScore(confidence);
        message.setTokensUsed(tokensUsed);
        message.setResponseTimeMs(responseTime);
        message.setCreatedAt(LocalDateTime.now());

        if (sources != null && !sources.isEmpty()) {
            String sourcesStr = sources.stream()
                .map(AnswerResponse.Source::getDocumentName)
                .collect(Collectors.joining(", "));
            message.setSources(sourcesStr);
        }

        return messageRepository.save(message);
    }

    private List<AnswerResponse.Source> buildSources(List<RelevantDocument> relevantDocs) {
        List<AnswerResponse.Source> sources = new ArrayList<>();

        for (int i = 0; i < relevantDocs.size(); i++) {
            RelevantDocument doc = relevantDocs.get(i);

            AnswerResponse.Source source = AnswerResponse.Source.builder()
                .documentId(doc.getDocumentId())
                .documentName(doc.getDocumentName())
                .excerpt(truncateText(doc.getText(), 200))
                .relevanceScore(doc.getScore())
                .isPrimary(i == 0)
                .build();

            sources.add(source);
        }

        return sources;
    }

    private Double calculateConfidence(List<RelevantDocument> results) {
        if (results.isEmpty()) {
            return 0.0;
        }

        double avgScore = results.stream()
            .mapToDouble(RelevantDocument::getScore)
            .average()
            .orElse(0.0);

        return Math.min(avgScore, 1.0);
    }

    private String truncateText(String text, int maxLength) {
        if (text == null || text.length() <= maxLength) {
            return text;
        }
        return text.substring(0, maxLength) + "...";
    }

    private AnswerResponse createNoResultsResponse(Message userMessage) {
        String answer = "Sorry, I couldn't find relevant information in the documents for your question. " +
                       "Try rephrasing the question or make sure the information exists in the documents.";

        Message assistantMessage = new Message();
        assistantMessage.setContent(answer);
        assistantMessage.setRole(MessageRole.ASSISTANT);
        assistantMessage.setChat(userMessage.getChat());
        assistantMessage.setParentMessageId(userMessage.getId());
        assistantMessage.setConfidenceScore(0.0);
        assistantMessage = messageRepository.save(assistantMessage);

        return AnswerResponse.builder()
                .answer(answer)
                .success(true)
                .confidence(0.0)
                .messageId(assistantMessage.getId())
                .timestamp(LocalDateTime.now())
                .suggestions(List.of(
                    "Rephrase the question",
                    "Check if the information exists in the documents",
                    "Upload additional documents"
                ))
                .build();
    }

    private AnswerResponse createErrorResponse(String errorMessage) {
        return AnswerResponse.builder()
                .success(false)
                .errorMessage(errorMessage)
                .timestamp(LocalDateTime.now())
                .build();
    }

    @lombok.Data
    private static class RelevantDocument {
        private String text;
        private Double score;
        private Long documentId;
        private String documentName;
    }
}